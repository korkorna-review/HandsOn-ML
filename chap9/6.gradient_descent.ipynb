{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사 하강법 구현\n",
    "\n",
    "* 그래디언트 수동 구현\n",
    "* 텐서플로의 자동 미분 기능을 이용한 자동 계싼\n",
    "* 텐서플로에 내장된 [옵티마이저](https://goo.gl/e7ptdr)(tf.train.Optimzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.34476576,  0.98214266, ..., -0.04959654,\n",
       "         1.05254828, -1.32783522],\n",
       "       [ 1.        ,  2.33223796, -0.60701891, ..., -0.09251223,\n",
       "         1.04318455, -1.32284391],\n",
       "       [ 1.        ,  1.7826994 ,  1.85618152, ..., -0.02584253,\n",
       "         1.03850269, -1.33282653],\n",
       "       ...,\n",
       "       [ 1.        , -1.14259331, -0.92485123, ..., -0.0717345 ,\n",
       "         1.77823747, -0.8237132 ],\n",
       "       [ 1.        , -1.05458292, -0.84539315, ..., -0.09122515,\n",
       "         1.77823747, -0.87362627],\n",
       "       [ 1.        , -0.78012947, -1.00430931, ..., -0.04368215,\n",
       "         1.75014627, -0.83369581]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 셋을 추출하고 \n",
    "# 모든 훈련 샘플에 편향에 대한 입력 특성(x0 = 1)을 추가\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]   # (m, 1)행렬을 만든뒤 housing데이터의 값을 채워넣음.\n",
    "housing_data_plus_bias\n",
    "\n",
    "# housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]   # (m, 1)행렬을 만든뒤 housing데이터의 값을 채워넣음.\n",
    "# housing_data_plus_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래디언트 수동 구현\n",
    "* random_uniform() 함수는 난수를 담은 텐서를 생성하는 노드를 그래프에 생성한다. numpy의 rand() 함수처럼 크기와 난수의 범위를 입력받는다.\n",
    "* assign() 함수는 변수에 새로운 값을 할당하는 노드를 생성한다.\n",
    "* 반복 루프는 훈련 단계를 계속 반복해서 실행하고 100번 반복마다 현재의 평균 제곱 에러(코드에서 mse 변수)를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")             # (20640, 9)\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')      # (20640, 1)\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')     # (9, 1)\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)  # theta 라는 변수에 아래 연산을 할당.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE 4.260892\n",
      "Epoch 100 MSE 0.8090007\n",
      "Epoch 200 MSE 0.6939066\n",
      "Epoch 300 MSE 0.6456543\n",
      "Epoch 400 MSE 0.61179495\n",
      "Epoch 500 MSE 0.5874149\n",
      "Epoch 600 MSE 0.5698319\n",
      "Epoch 700 MSE 0.55714893\n",
      "Epoch 800 MSE 0.5480005\n",
      "Epoch 900 MSE 0.5414016\n",
      "[[ 2.0685523 ]\n",
      " [ 0.7647554 ]\n",
      " [ 0.15040347]\n",
      " [-0.06102888]\n",
      " [ 0.10055514]\n",
      " [ 0.00785305]\n",
      " [-0.04062066]\n",
      " [-0.7300592 ]\n",
      " [-0.6892007 ]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()  # 변수 초기화\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동 미분 사용\n",
    "추후 기재.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = tf.gradients(mse, [theta])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 옵티마이저 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
